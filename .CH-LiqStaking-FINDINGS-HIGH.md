
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% HIGH & MEDIUM %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

# H01 - OperatorStakingPool::withdraw - LST tokens are not sent to the operator and they remain stuck in the contract forever



## Summary

**Links:** https://github.com/Cyfrin/2024-09-stakelink/blob/f5824f9ad67058b24a2c08494e51ddd7efdbb90b/contracts/linkStaking/OperatorStakingPool.sol#L132

The withdraw function updates shareBalances for the operator, but no LST tokens are sent to the operator. Also, there is no general withdraw function that would allow the contract owner to transfer LST out of the contract. So, those tokens remain stuck in the contract forever.


## Vulnerability Details

**Proof of Concept:**

Add the following test to operator-staking-pool.test.ts

```
it('withdraw does not send LST back to the operator', async () => {
  const { signers, accounts, opPool, lst } = await loadFixture(deployFixture)

  //account1 initially has 10000 LST
  assert.equal(fromEther(await lst.balanceOf(accounts[1])), 10000)

  //account1 deposits 1000 LST
  await lst.connect(signers[1]).transferAndCall(opPool.target, toEther(1000), '0x')
  assert.equal(fromEther(await lst.balanceOf(accounts[1])), 9000)

  //account1 withdraws 700 LST
  await opPool.connect(signers[1]).withdraw(toEther(700))
  
  //the internal accounting is correct
  assert.equal(fromEther(await opPool.getOperatorPrincipal(accounts[1])), 300)
  assert.equal(fromEther(await opPool.getOperatorStaked(accounts[1])), 300)  
  
  // !!! this currently fails !!! account1 should now hold 9700 LST, but holds only 9000 LST
  assert.equal(fromEther(await lst.balanceOf(accounts[1])), 9700)       
})
```


## Impact

As already mentioned above, operators cannot recover their LST and all deposited LST remains stuck in the contract forever.


## Tools Used

Manual Review

## Recommendations

Modify the _withdraw function

```diff
function _withdraw(address _operator, uint256 _amount) private {
    uint256 sharesAmount = lst.getSharesByStake(_amount);
    shareBalances[_operator] -= sharesAmount;
    totalShares -= sharesAmount;
    
+   lst.transfer(_operator, _amount);

    emit Withdraw(_operator, _amount, sharesAmount);
}
```

Ideally, the contract should also have a function that allows the owner to withdraw LST.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


# H02 - OperatorVCS::initialize - wrong initialization for GlobalVaultState.depositIndex

## Summary

**Link:** https://github.com/Cyfrin/2024-09-stakelink/blob/f5824f9ad67058b24a2c08494e51ddd7efdbb90b/contracts/linkStaking/OperatorVCS.sol#L79

The value for GlobalVaultState.depositIndex is initialized with the wrong value, which causes several function, like: queueVaultRemoval and _depositToVaults to behave in a wrong way.


## Vulnerability Details

When the OperatorVCS contract is deployed, the initialize function will run automatically and the contract will be initialized to version 3 (because of the presence of the reinitializer(3) modifier). A version of the VaultControllerStrategy contract will already have been deployed previously, so, at this point, the token state variable will have a different value than address(0) and the else block in the code will be executed:

```
else {
    globalVaultState = GlobalVaultState(5, 0, 0, uint64(maxDepositSizeBP + 1));
    maxDepositSizeBP = _maxDepositSizeBP;
    delete fundFlowController;
    vaultMaxDeposits = _vaultMaxDeposits;
}
```

The problem here is that the globalVaultState.depositIndex will be set to the wrong value: uint64(maxDepositSizeBP + 1). maxDepositSizeBP will be a high value (something around 9000) and the number of vaults will be much lower than this value.
 

## Impact

**The globalVaultState.depositIndex is used in the queueVaultRemoval function:**

```
function queueVaultRemoval(uint256 _index) external {
...
if (_index < globalVaultState.depositIndex) {
    uint256 group = _index % globalVaultState.numVaultGroups;
    uint256[] memory groups = new uint256[](1);
    groups[0] = group;
    fundFlowController.updateOperatorVaultGroupAccounting(groups);

    // if possiible, remove vault right away
    if (vaults[_index].claimPeriodActive()) {
        removeVault(vaultsToRemove.length - 1);
    }
}
```

Because of the wrong initialization of the depositIndex, the specified _index will always be lower than the depositIndex, even for vaults that are not part of a vault group. This means, the fundFlowController will potentially update the internal accounting of a vault group that should not be updated. Also, because the specified vault _index may not be part of a group, a vault that should not be removed may be removed.


**The globalVaultState.depositIndex is also used in the _depositToVaults function:**

In the following code section, vaultIndex will never be bigger than the globalState.depositIndex, so, this will never revert, even if an invalid _vaultId is provided:

```
function _depositToVaults(uint256 _toDeposit, uint256 _minDeposits, uint256 _maxDeposits, uint64[] memory _vaultIds) {
...
for (uint256 i = 0; i < _vaultIds.length; ++i) {
    uint256 vaultIndex = _vaultIds[i];
     
    //this will not revert, even for invalid vaultIndex
    if (vaultIndex >= globalState.depositIndex) revert InvalidVaultIds();

```



In the following code section, the group.withdrawalIndex will never be bigger than the globalState.depositIndex, which means, the group.withdrawalIndex may be set to the wrong value: 

```
...
if (deposits == 0 && vaultIndex == group.withdrawalIndex) {
    group.withdrawalIndex += uint64(globalState.numVaultGroups);
    if (group.withdrawalIndex > globalState.depositIndex) { 
        //this code will never be executed                   
        group.withdrawalIndex = uint64(groupIndex);
    }
}
```

In the following code section, the variable i will be set to an index thats far greater than the current number vaults. This means, the while loop will never be executed, it is not possible to deposit into the vault and the correct depositindex cannot be set

```
...
uint256 i = globalState.depositIndex;

//loop will never be executed
while (i < numVaults) {
    IVault vault = vaults[i];
    uint256 deposits = vault.getPrincipalDeposits();
    uint256 canDeposit = _maxDeposits - deposits;
    
    ...
    
    //deposit cannot be done
    if (toDeposit > canDeposit) {
       vault.deposit(canDeposit);
       
    ...
    
     ++i;
}

//correct depositIndex cannot be set
globalVaultState.depositIndex = uint64(i);

```
 

## Tools Used

Manual Review


## Recommendations

Replace the else block of the initialize function with the following code:

```diff
else {
+   uint64 currentDepositIndex = globalVaultState.depositIndex;
+   globalVaultState = GlobalVaultState(5, 0, 0, currentDepositIndex);
-   globalVaultState = GlobalVaultState(5, 0, 0, uint64(maxDepositSizeBP + 1));
    maxDepositSizeBP = _maxDepositSizeBP;
    delete fundFlowController;
    vaultMaxDeposits = _vaultMaxDeposits;
}
```



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

# M01 - LSTRewardsSplitter::addFee - by accident, the same fee receiver could be added several times to the same RewardsSplitter

## Summary

**Link:** https://github.com/Cyfrin/2024-09-stakelink/blob/f5824f9ad67058b24a2c08494e51ddd7efdbb90b/contracts/core/lstRewardsSplitter/LSTRewardsSplitter.sol#L141

The is no control on the addFee function that would prevent the contract owner from accidentially adding the same fee receiver several times.

## Vulnerability Details

**Proof of Concept:**

Add the following test to lst-rewards-splitter.test.ts:

```
it.only('the same feeReceiver can be added several times to to a RewardsSplitter', async () => {
  const { accounts, controller, token, splitter0 } = await loadFixture(deployFixture)

  await token.transferAndCall(controller.target, toEther(100), '0x')
  await token.transfer(splitter0.target, toEther(100))

  //by accident, account6 is added a second time as fee receiver
  await splitter0.addFee(accounts[6], 2000)

  await splitter0.splitRewards()

  //the same fee receiver is added twice to the fees array
  console.log("Fees: ", await splitter0.getFees())

  //the balance of splitter0 should be 170, but because account6 got added a second time, it is only 150
  assert.equal(fromEther(await splitter0.principalDeposits()), 150)
  assert.equal(fromEther(await token.balanceOf(splitter0.target)), 150)
  
  assert.equal(fromEther(await token.balanceOf(accounts[5])), 10)
  //account6 should only receive a 20% fee, but it gets an accumulated fee of 40%
  assert.equal(fromEther(await token.balanceOf(accounts[6])), 40)
})
```

## Impact

This would cause an indirect loss of funds, because the feeReceiver address (that got added more than once to the fees array) would receive more funds that it is entitled to.


## Tools Used

Manual Review


## Recommendations

Modify the addFee function in the following way:

```
error FeeReceiverAlreadyExists();

function addFee(address _receiver, uint256 _feeBasisPoints) external onlyOwner {
    for (uint256 i = 0; i < fees.length; ++i) {
        if (fees[i].receiver == _receiver) revert FeeReceiverAlreadyExists();
    }

    fees.push(Fee(_receiver, _feeBasisPoints));
    if (_totalFeesBasisPoints() > 10000) revert FeesExceedLimit();
}
```




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LOW %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

# L01 - LSTRewardsSplitterController::removeSplitter - LSTRewardSplitter cannot be removed if there are undistributed rewards

## Link: https://github.com/Cyfrin/2024-09-stakelink/blob/f5824f9ad67058b24a2c08494e51ddd7efdbb90b/contracts/core/lstRewardsSplitter/LSTRewardsSplitterController.sol#L138


The function evaluates the current splitter balance:

```
uint256 balance = IERC20(lst).balanceOf(address(splitter));
```

If there is a balance and the balance is different from the principalDeposits, splitRewards is called on the splitter that should be removed.

```
if (balance != principalDeposits) splitter.splitRewards();
```

And, finally, the withdraw function is called on the splitter: 

```
splitter.withdraw(balance, _account);
```

The problem here is, that the initially retrieved balance value (see above) is passed to the withdraw function. However, after calling "splitRewards", the balance of the splitter will change (it will  be lower). 

In the LSTRewardsSplitter::withdraw function, the following line will be executed with an _amount value that is bigger than the principalDeposits value

```
principalDeposits -= _amount;
```

And, this will cause a panic error (arithmetic operation overflowed outside of an unchecked block)


## Proof of concept:

Add the following test to lst-rewards-splitter.test.ts: 

```
it('removeSplitter should fail if there are undistributed rewards', async () => {    
  const { accounts, controller, token, splitter0 } = await loadFixture(deployFixture)

  await token.transferAndCall(controller.target, toEther(100), '0x')
  await token.transfer(splitter0.target, toEther(100)) //simulate rewards

  await expect(controller.removeSplitter(accounts[0])).to.be.reverted
})
```


## Recommendations

Before calling splitter.withdraw... in the removeSplitter function, update the balance:

```
...
balance = IERC20(lst).balanceOf(address(splitter));
splitter.withdraw(balance, _account);
...
``` 


# L02 - WithdrawalPool ::updateWithdrawalBatchIdCutoff - the withdrawalBatchIdCutoff is not correctly set 

## Link: https://github.com/Cyfrin/2024-09-stakelink/blob/f5824f9ad67058b24a2c08494e51ddd7efdbb90b/contracts/core/priorityPool/WithdrawalPool.sol#L393


The value of newWithdrawalBatchIdCutoff is set at the end of the second for-loop, but it should be set at the beginning of the loop, because, if the "break" statement is executed, the correct value of newWithdrawalBatchIdCutoff won't be set.


## Proof of concept:

Add the following test to withdrawal-pool.test.ts: 

```
it('withdrawalBatchIdCutoff is not correctly set in updateWithdrawalBatchIdCutoff', async () => {
  const { signers, accounts, withdrawalPool } = await loadFixture(deployFixture)

  //we queue 3 withdrawals for accounts[0] => this will add 3 new Withdrawals (withdrawalId 1 to 3) to the queuedWithdrawals array
  await withdrawalPool.queueWithdrawal(accounts[0], toEther(100)) 
  await withdrawalPool.queueWithdrawal(accounts[0], toEther(100)) 
  await withdrawalPool.queueWithdrawal(accounts[0], toEther(100)) 
  
  //we make a first deposit of 200 => this will add a new WithdrawalBatch (withdrawalBatch 1) to the withdrawalBatches array 
  //and this will service withdrawalId 1 & 2 => indexOfNextWithdrawal = 3
  await withdrawalPool.deposit(toEther(200)) 

  //we make a second deposit of 100 => this will add a new WithdrawalBatch (withdrawalBatch 2) to the withdrawalBatches array 
  //and this will service withdrawalId 3 => indexOfNextWithdrawal = 4
  await withdrawalPool.deposit(toEther(100)) 
  
  //perform a withdraw for accounts[0] => but, only for withdrawalId 1 & 2 => both are in withdrawalBatch 1
  await withdrawalPool.connect(signers[0]).withdraw([ 1,2 ], [1,1])  

  //before calling updateWithdrawalBatchIdCutoff, the withdrawalBatchIdCutoff will be 0
  console.log("withdrawalBatchIdCutoff 1: ", await withdrawalPool.withdrawalBatchIdCutoff()) //0
  assert.equal(await withdrawalPool.withdrawalBatchIdCutoff(), 0)

  await withdrawalPool.updateWithdrawalBatchIdCutoff()

  //after calling updateWithdrawalBatchIdCutoff, the withdrawalBatchIdCutoff should be 2, but it is actually 1
  //all batches before withdrawalBatch 2 have had all withdrawal requests fully withdrawn => so, the correct value is 2 !
  console.log("withdrawalBatchIdCutoff 2: ", await withdrawalPool.withdrawalBatchIdCutoff()) //1 => should be 2 !!!
  
  //the following test fails until necessary corrections are made in updateWithdrawalBatchIdCutoff
  assert.equal(await withdrawalPool.withdrawalBatchIdCutoff(), 2)
})
```


## Recommendations

Replace the second for-loop in the updateWithdrawalBatchIdCutoff function with the following code: 

```
...
for (uint256 i = newWithdrawalBatchIdCutoff; i < numBatches; ++i) {
    newWithdrawalBatchIdCutoff = i;
    
    if (withdrawalBatches[i].indexOfLastWithdrawal >= newWithdrawalIdCutoff) {
        break;
    }

    newWithdrawalBatchIdCutoff = i;
}
...
``` 


# L03 - StakingPool - Owner cannot change the maximum allowed value for totalFeesBasisPoints 

## Links:

https://github.com/Cyfrin/2024-09-stakelink/blob/f5824f9ad67058b24a2c08494e51ddd7efdbb90b/contracts/core/StakingPool.sol#L76
https://github.com/Cyfrin/2024-09-stakelink/blob/f5824f9ad67058b24a2c08494e51ddd7efdbb90b/contracts/core/StakingPool.sol#L349
https://github.com/Cyfrin/2024-09-stakelink/blob/f5824f9ad67058b24a2c08494e51ddd7efdbb90b/contracts/core/StakingPool.sol#L373


The contract uses hardcoded ("magic number") values for the max allowed totalFeesBasisPoints, which prevents the contract owner from modifying this value.


## Recommendations

Add an external setter function with an onlyOwner modifer and a corresponding state variable to the contract - similar to the setUnusedDepositLimit function.


# L04 - OperatorVCS::initialize - when the contract is upgraded to version3 there is no need to add additional Vault Groups

## Links: https://github.com/Cyfrin/2024-09-stakelink/blob/f5824f9ad67058b24a2c08494e51ddd7efdbb90b/contracts/linkStaking/OperatorVCS.sol#L85C9-L87C10

Vault Groups only need to be added when the contract is first deployed, when the contract is upgraded to version 3 (reinitializer(3)), those vaultGroups exist already and 5 additional Vault Groups will be added.


## Recommendations

Place the code section that adds the Vault Groups within the if-block in the initialize function:

```diff
function initialize(
    address _token,
    address _stakingPool,
    address _stakeController,
    address _vaultImplementation,
    Fee[] memory _fees,
    uint256 _maxDepositSizeBP,
    uint256 _vaultMaxDeposits,
    uint256 _operatorRewardPercentage,
    address _vaultDepositController
) public reinitializer(3) {
    if (address(token) == address(0)) {
        __VaultControllerStrategy_init(
            _token,
            _stakingPool,
            _stakeController,
            _vaultImplementation,
            _fees,
            _maxDepositSizeBP,
            _vaultMaxDeposits,
            _vaultDepositController
        );

        if (_operatorRewardPercentage > 10000) revert InvalidPercentage();
        operatorRewardPercentage = _operatorRewardPercentage;
        globalVaultState = GlobalVaultState(5, 0, 0, 0);
        
+       for (uint64 i = 0; i < 5; ++i) {
+           vaultGroups.push(VaultGroup(i, 0));
+       }
    } else {
        globalVaultState = GlobalVaultState(5, 0, 0, uint64(maxDepositSizeBP + 1));
        maxDepositSizeBP = _maxDepositSizeBP;
        delete fundFlowController;
        vaultMaxDeposits = _vaultMaxDeposits;
    }

-    for (uint64 i = 0; i < 5; ++i) {
-        vaultGroups.push(VaultGroup(i, 0));
-    }
}
```





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% TEST %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

# VaultDepositController::withdraw missing access control - anyone can withdraw funds

## Links: https://github.com/Cyfrin/2024-09-stakelink/blob/f5824f9ad67058b24a2c08494e51ddd7efdbb90b/contracts/linkStaking/base/VaultControllerStrategy.sol#L111

## Summary

Summary...

## Vulnerability Details

Describe details...

**Proof of Concept:**

## Impact

Describe details...

## Tools Used

Manual Review

## Recommendations

Add the following mapping to the RankedBattle contract:

```
/// @notice Indicates whether we have already called the updateBattleRecord function for a given round and token.
mapping(uint256 => mapping(uint256 => bool)) public updateBattleRecordAlreadyCalled;
```










# M01 - RankedBattle::updateBattleRecord can be called several times for the same round and tokenId 

## Title: RankedBattle::updateBattleRecord can be called several times for the same round and tokenId 

## Links: https://github.com/code-423n4/2024-02-ai-arena/blob/cd1a0e6d1b40168657d1aaee8223dc050e15f8cc/src/RankedBattle.sol#L322

## Impact

The updateBattleRecord in the RankedBattle contract can potentially be called several times by the game server for the same round and tokenId, which would falsify the amount of points and NRN tokens distributed to the corresponding fighter NFT.


## Proof of Concept

Add the following test to the RankedBattle.t.sol file:

```
function testCallingUpdateBattleRecordSeveralTimesShouldFail() public {
  
}
```

According to the values provided for the updateBattleRecord() function, the player should only get 40500 points. However, because the updateBattleRecord() function was called twice for the same round and tokenId by the game server, the player received 81000 points. 


## Tools Used

Manual Review

## Recommended Mitigation Steps

Add the following mapping to the RankedBattle contract:

```
/// @notice Indicates whether we have already called the updateBattleRecord function for a given round and token.
mapping(uint256 => mapping(uint256 => bool)) public updateBattleRecordAlreadyCalled;
```









